{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed2a9198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cohere\n",
    "import dvc.api as DvcApi\n",
    "from dotenv import load_dotenv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d87075f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(\"../..\")))\n",
    "sys.path.append(os.path.abspath(os.path.join(\"../scripts\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38abf9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prompt_functions as promptf\n",
    "import evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8432c26",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "load_dotenv(encoding='utf-16')\n",
    "\n",
    "api_key = os.getenv('apikey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ab05fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and retrieve a Cohere API key from os.cohere.ai\n",
    "co = cohere.Client(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "973c2422",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_extract = evaluations.EntityExtraction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc829ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2edcf1b",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER)  with Generative Model of Cohere\n",
    "\n",
    "In this notebook we use Cohere's generative models to extract entities from a job description. We make use of sturctured generation based on providing multiple examples in the prompt.\n",
    "\n",
    "The data are job descriptions (together named entities) and relationships between entities in json format. In this preliminary work we will not consider the relationships as NER alone is not enough to achieve this.\n",
    "\n",
    "- Dataset 1: For development and training\n",
    "- Dataset 2: For testing and final reporting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e236ef",
   "metadata": {},
   "source": [
    "## Preparing examples for the prompt\n",
    "\n",
    "In our prompt, we'll present the model with examples of job descriptions and the type of output we're after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b586335",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/relations_dev.json\"\n",
    "repo = \"../\"\n",
    "version = \"v2\"\n",
    "\n",
    "data_url = DvcApi.get_url(path = path, repo = repo, rev = version) #could be tag or git commit\n",
    "data_dev = pd.read_json(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e58b331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we put extracted entities in a clearer way\n",
    "\n",
    "df = data_dev.drop(columns = ['tokens', 'relations'])\n",
    "df['tokens'] = data_dev['tokens'].apply(lambda x: promptf.streamline_tokens(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bcf0f0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bachelor's degree in Mechanical Engineering or Physical Science 3+ years track record of developing or specifying fiber optic cables and connector related products Knowledge of fiber optic component, cabling, and interconnect products, technologies, and standards Experience in statistical data analysis Experience with product life cycle management (PLM) process Experience providing solutions to problems and meeting deadlines Experience engaging stakeholders PREFERRED Advanced degree Experience using a software tool for statistical data analysis such as JMP Experience using Agile as product life-cycle management tool Data center or other mission critical development experience</td>\n",
       "      <td>DIPLOMA: Bachelor\\nDIPLOMA_MAJOR: Mechanical Engineering\\nDIPLOMA_MAJOR: Physical Science\\nEXPERIENCE: 3+ years\\nSKILLS: developing\\nSKILLS: fiber optic cables\\nSKILLS: connector related products</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       document  \\\n",
       "0  Bachelor's degree in Mechanical Engineering or Physical Science 3+ years track record of developing or specifying fiber optic cables and connector related products Knowledge of fiber optic component, cabling, and interconnect products, technologies, and standards Experience in statistical data analysis Experience with product life cycle management (PLM) process Experience providing solutions to problems and meeting deadlines Experience engaging stakeholders PREFERRED Advanced degree Experience using a software tool for statistical data analysis such as JMP Experience using Agile as product life-cycle management tool Data center or other mission critical development experience   \n",
       "\n",
       "                                                                                                                                                                                                tokens  \n",
       "0  DIPLOMA: Bachelor\\nDIPLOMA_MAJOR: Mechanical Engineering\\nDIPLOMA_MAJOR: Physical Science\\nEXPERIENCE: 3+ years\\nSKILLS: developing\\nSKILLS: fiber optic cables\\nSKILLS: connector related products  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8848c7eb",
   "metadata": {},
   "source": [
    "## Zero-Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e621a1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of examples is zero\n",
    "\n",
    "num_Ex = 0\n",
    "\n",
    "prompt = promptf.make_prompt(data_dev, num_Ex, same_file= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2a52768",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOCUMENT: Bachelor's degree in Mechanical Engineering or Physical Science 3+ years track record of developing or specifying fiber optic cables and connector related products Knowledge of fiber optic component, cabling, and interconnect products, technologies, and standards Experience in statistical data analysis Experience with product life cycle management (PLM) process Experience providing solutions to problems and meeting deadlines Experience engaging stakeholders PREFERRED Advanced degree Experience using a software tool for statistical data analysis such as JMP Experience using Agile as product life-cycle management tool Data center or other mission critical development experience\n",
      "EXTRACTED TEXT:\n"
     ]
    }
   ],
   "source": [
    "# let's look at the prompt\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "641e2537",
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction = co.generate( model = 'large', prompt = prompt, max_tokens = 100, temperature = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a06b2c20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Senior Product Manager will be responsible for the development and management of fiber optic cable and connector products. The Senior Product Manager will be responsible for the development of new products and the management of existing products. The Senior Product Manager will be responsible for the development of product specifications, product requirements, and product life cycle management. The Senior Product Manager will be responsible for the development of product marketing materials and the management of product marketing. The Senior Product Manager will be responsible for the development of product training materials\n"
     ]
    }
   ],
   "source": [
    "print(extraction.generations[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d569d24a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIPLOMA: Bachelor\n",
      "DIPLOMA_MAJOR: Mechanical Engineering\n",
      "DIPLOMA_MAJOR: Physical Science\n",
      "EXPERIENCE: 3+ years\n",
      "SKILLS: developing\n",
      "SKILLS: fiber optic cables\n",
      "SKILLS: connector related products\n"
     ]
    }
   ],
   "source": [
    "# compared to the expected result\n",
    "\n",
    "print(df.iloc[num_Ex]['tokens'])\n",
    "#print(promptf.test_labels(data_dev, num_Ex))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2a582a",
   "metadata": {},
   "source": [
    "As expected, zero-shot learning doesn't give us a good answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b08495",
   "metadata": {},
   "source": [
    "_________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b759a06",
   "metadata": {},
   "source": [
    "## Few-Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdc61f2",
   "metadata": {},
   "source": [
    "### 1. Include 1-4 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e212158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we include 1 example\n",
    "\n",
    "num_Ex = 1\n",
    "prompt = promptf.make_prompt(data_dev, num_Ex, same_file= True)\n",
    "\n",
    "extraction = co.generate( model = 'large', prompt = prompt, max_tokens = 100, temperature = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7404d39f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DIPLOMA: Bachelor\n",
      "DIPLOMA_MAJOR: Computer Science\n",
      "DIPLOMA_MAJOR: Software Engineering\n",
      "EXPERIENCE: 10+ years\n",
      "SKILLS: release automation engineering\n",
      "SKILLS: CI/CD or related roles\n",
      "SKILLS: consumer electronics devices\n",
      "SKILLS: technical teams\n",
      "SKILLS: performance management\n",
      "--\n",
      "DOCUMENT: Bachelor's degree in Computer Science or related field\n",
      "\n",
      "compared to the expected result:\n",
      "\n",
      "EXPERIENCE: 10+ years\n",
      "SKILLS: software engineering\n",
      "EXPERIENCE: 5+ years\n",
      "SKILLS: technical management\n",
      "SKILLS: release engineering\n",
      "SKILLS: tools engineering\n",
      "SKILLS: DevOps\n",
      "DIPLOMA: BS/MS\n",
      "DIPLOMA_MAJOR: Computer Science\n"
     ]
    }
   ],
   "source": [
    "print(extraction.generations[0].text)\n",
    "\n",
    "print('\\ncompared to the expected result:\\n')\n",
    "\n",
    "print(df.iloc[num_Ex]['tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52a9567",
   "metadata": {},
   "source": [
    "The model is extracting too many labels.\n",
    "\n",
    "To solve this we lower the maximum number of tokens it can generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0306987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we include 2 examples\n",
    "\n",
    "num_Ex = 2\n",
    "prompt = promptf.make_prompt(data_dev, num_Ex, same_file= True)\n",
    "\n",
    "extraction = co.generate( model = 'large', prompt = prompt, max_tokens = 50, temperature = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b608996a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EXPERIENCE: 3+ years\n",
      "SKILLS: Swift\n",
      "SKILLS: Objective-C\n",
      "SKILLS: iOS internals\n",
      "SKILLS: app from scratch\n",
      "SKILLS: portfolio of apps featured in\n",
      "\n",
      "compared to the expected result:\n",
      "\n",
      "EXPERIENCE: 3+ years\n",
      "SKILLS: Swift & Objective-C\n"
     ]
    }
   ],
   "source": [
    "print(extraction.generations[0].text)\n",
    "\n",
    "print('\\ncompared to the expected result:\\n')\n",
    "\n",
    "print(df.iloc[num_Ex]['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74798afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we include 3 examples\n",
    "\n",
    "num_Ex = 3\n",
    "prompt = promptf.make_prompt(data_dev, num_Ex, same_file= True)\n",
    "\n",
    "extraction = co.generate( model = 'large', prompt = prompt, max_tokens = 50, temperature = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f3b53b5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EXPERIENCE: 8+ years\n",
      "SKILLS: software engineering\n",
      "EXPERIENCE: 5+ years\n",
      "SKILLS: people management\n",
      "SKILLS: managing leaders\n",
      "SKILLS: managing remotely\n",
      "SKILLS\n",
      "\n",
      "compared to the expected result:\n",
      "\n",
      "EXPERIENCE: 8+ years\n",
      "SKILLS: software engineering\n",
      "EXPERIENCE: 5+ years\n",
      "SKILLS: people management\n",
      "SKILLS: managing leaders\n"
     ]
    }
   ],
   "source": [
    "print(extraction.generations[0].text)\n",
    "\n",
    "print('\\ncompared to the expected result:\\n')\n",
    "\n",
    "print(df.iloc[num_Ex]['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b88b213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we include 4 examples\n",
    "\n",
    "num_Ex = 4\n",
    "prompt = promptf.make_prompt(data_dev, num_Ex, same_file= True)\n",
    "\n",
    "extraction = co.generate( model = 'large', prompt = prompt, max_tokens = 50, temperature = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "75f1bc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EXPERIENCE: 7+ years\n",
      "SKILLS: C++\n",
      "EXPERIENCE: 5+ years\n",
      "SKILLS: software development\n",
      "SKILLS: shipping\n",
      "SKILLS: products\n",
      "--\n",
      "DOCUMENT\n",
      "\n",
      "compared to the expected result:\n",
      "\n",
      "DIPLOMA: BS\n",
      "DIPLOMA_MAJOR: Computer Science\n",
      "EXPERIENCE: 7+ years\n",
      "SKILLS: C++\n",
      "SKILLS: C++11\n",
      "EXPERIENCE: 5+ years\n",
      "SKILLS: creating software for real-time environments\n",
      "SKILLS: games\n",
      "SKILLS: robotics\n",
      "EXPERIENCE: 2+ years\n",
      "SKILLS: managing software engineers\n"
     ]
    }
   ],
   "source": [
    "print(extraction.generations[0].text)\n",
    "\n",
    "print('\\ncompared to the expected result:\\n')\n",
    "\n",
    "print(df.iloc[num_Ex]['tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70de5b18",
   "metadata": {},
   "source": [
    "### 3. Validate using 5 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7000f6e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 984 ms\n",
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "extracted = []\n",
    "\n",
    "for i in range(5, len(data_dev)):\n",
    "    index = i\n",
    "    prompt = promptf.make_prompt(data_dev, index, numEx= 5, same_file= True)\n",
    "    \n",
    "    extraction = co.generate( model = 'large', prompt = prompt, max_tokens = 50, temperature = 0.5)\n",
    "    \n",
    "    extracted.append(extraction.generations[0].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25305686",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.drop(range(5), inplace= True)\n",
    "\n",
    "df['extractedEntities']  = extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24ceabd",
   "metadata": {},
   "source": [
    "Next we have to evaluate the model \n",
    "\n",
    "- First we try a very naive method by comparing the extracted entities as a whole "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26974ecd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.0%\n"
     ]
    }
   ],
   "source": [
    "# Compare the tokens to the extracted text\n",
    "df['correct'] = (df['tokens'].str.lower() == df['extractedEntities'].str.lower()).astype(int)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f'Accuracy {df[\"correct\"].mean() *100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9ebe161",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= df['tokens'].iloc[0]\n",
    "y= df['extractedEntities'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e207cee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.5,\n",
       " 'Precision': 0.3333333333333333,\n",
       " 'Missing': 0.5,\n",
       " 'OverShooting': 0.6666666666666666}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_extract.metrics_str(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdac18a4",
   "metadata": {},
   "source": [
    "The naive metric clearly doesn't give us any insight.\n",
    "\n",
    "- Next step is to use a more involved metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f136369b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = entity_extract.metrics_df(df['tokens'], df['extractedEntities'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3010437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy        0.240952\n",
       "Precision       0.318095\n",
       "Missing         0.759048\n",
       "OverShooting    0.681905\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e9a435",
   "metadata": {},
   "source": [
    "_________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "846da22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom concurrent.futures import ThreadPoolExecutor\\n\\nextracted = []\\n# Run the model to extract the entities\\nwith ThreadPoolExecutor(max_workers=8) as executor:\\n    for i in executor.map(cohereMovieExtractor.extract, test_df['text']):\\n        extracted.append(str(i).strip())\\n# Save results\\ntest_df['extracted_text'] = extracted\\n\\n\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "extracted = []\n",
    "# Run the model to extract the entities\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    for i in executor.map(cohereMovieExtractor.extract, test_df['text']):\n",
    "        extracted.append(str(i).strip())\n",
    "# Save results\n",
    "test_df['extracted_text'] = extracted\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7131b07e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef extract(self, example):\\n    extraction = co.generate(model=\\'large\\', prompt=self.make_prompt(example), max_tokens=10, \\n                             temperature=0.1, stop_sequences=[\"\\n\"])\\n    return(extraction.generations[0].text[:-1])\\n    \\n    extraction = co.generate( model = \\'large\\', prompt = prompt, max_tokens = 100, temperature = 0.1,\\n                        stop_sequences = [\"--\"])\\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def extract(self, example):\n",
    "    extraction = co.generate(model='large', prompt=self.make_prompt(example), max_tokens=10, \n",
    "                             temperature=0.1, stop_sequences=[\"\\n\"])\n",
    "    return(extraction.generations[0].text[:-1])\n",
    "    \n",
    "    extraction = co.generate( model = 'large', prompt = prompt, max_tokens = 100, temperature = 0.1,\n",
    "                        stop_sequences = [\"--\"])\n",
    "\"\"\"\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
